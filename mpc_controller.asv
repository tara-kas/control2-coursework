% MPC Controller design with YALMIP

% Brief: Implement a constrained MPC in YALMIP and evaluate it under varied design/constraint
% scenarios (e.g., with/without terminal cost; input magnitude and input-rate limits).

function y = mpc_controller(inputs)
% INPUTS:
%   curr_x  - current state [theta; alpha; theta_dot; alpha_dot]
%   curr_r  - reference position (scalar)
%   t       - time step (t == 0 initialises controller)
% OUTPUT:
%   y       - optimal control input

curr_x = inputs(1:4);
curr_r = inputs(5);
t = inputs(6);

persistent Controller  % preserves optimiser for reuse and improve execution speed

if t == 0     
    %% initialise all the vars once
    % simulink
    ts = 0.002;         % sampling time (s)
    nx = 4;             % size of states
    nu = 1;             % size of input

    % motor
    Rm = 7.5;           % armature resistance (ohms)
    kt = 0.042;         % torque constant (Nm/A)
    km = 0.042;         % back-emf (Vs/rad)

    % rotary arm
    mr = 0.095;         % arm mass (kg)
    r = 0.085;          % arm length - pivot to pendulum joint (m)
    Jr = 2.41e-4;       % arm moment of inertia (kgm^2)
    br = 1e-3;          % arm viscous damping coeff (Nms/rad)

    % pendulum link
    mp = 0.024;         % pendulum mass (kg)
    Lp = 0.129;         % pendulum length (m)
    l = 0.0645;         % pendulum centre of mass (m)
    Jp = 1.33e-4;       % pendulum moment of inertia (kgm^2)
    bp = 5.0e-5;        % pendulum viscous damping coeff (Nms/rad)

    g = 9.81;           % gravitational constant (m/s^2)

    %% state variables and sub-vars
    % M = [ (Jr + mp * r^2),  (-mp * l * r);
    %       (mp * l * r),     (-Jp) ];
    % 
    % a31 = 0;
    % a32 = (-mp^2 * l^2 * r * g) / det(M);
    % a33 = (Jp * ((kt * km) / Rm + br)) / det(M);
    % a34 = (bp * mp * l * r) / det(M);
    % b31 = ((-kt * Jp) / Rm) / det(M);
    % 
    % a41 = 0;
    % a42 = (-(Jr + mp * r^2) * mp * g * l) / det(M);
    % a43 = ((mp * l * r) * ((kt * km) / Rm) + br) / det(M);
    % a44 = ((Jr + mp * r^2) * bp) / det(M);
    % b41 = (-(mp * l * r) * (kt / Rm)) / det(M);

    % A, B, C, D discrete matrices
    Ad = [1,   0,   0.0020,   0;
         0,   1.0000,   0,   0.0020;
         0, 0.1103, 0.9909, -0.0004;
         0, 0.3372, -0.0090, 0.9989];

    Bd = [0, 0, 0.0412, 0.0407]';

    % CHECK THIS LOGIC v
    Cd = [1, 0, 0, 0;      % since C in form [I 0],
         0, 1, 0, 0];     % want both theta and alpha in output vector

    Dd = 0;                % no direct feedthrough


    %% steady state mapping SSM
    % solves (A - I)*xss + B*uss = 0
    % C*xss = ref
    % => M*[xss; uss] = [0;0;0;0;r1;r2]

    % Mss dimensions should be 6x5 (A is 4x4, C is 2x4 => 4+2 = 6)
                                %  ([xss; uss] is 4x1+1x1 = 5)
    Mss = [(Ad-eye(4)) Bd;
           Cd          zeros(2,1)];


    %% MPC costs weights and horizon
    % Q weights the state tracking err (x - xss)
    % since (x-xss) is 4x1, Q should be 4x4
    Q = eye(4); %REPLACE W/ GAINS

    % R weights the input tracking err (u - uss)
    % since (u-uss) is 1x1, R should be scalar
    R = 1;      %REPLACE W/ GAINS

    % prediction horizon
    N = 10;      %REPLACE W/ GAINS

    du_max = 5; % max change in input per sample (tune as needed)

    % constraints (hard limits)
    % input bounds/actuator saturation
    u_min = -10;
    u_max = 10;


    % state bounds [theta; alpha; theta_dot; alpha_dot]
    x_min = [-2*pi; -2*pi; -inf; -inf];   %REPLACE
    x_max = -x_min;       %REPLACE

   
    %% terminal cost from LQR
    % P solves the discrete Riccati equation for (A,B,Q,R)
    [~,P,~] = dlqr(Ad,Bd,Q,R);


    %% YALMIP time
    yalmip("clear");

    % parameters
    u = sdpvar(repmat(nu,1,N), repmat(1,1,N), 'full'); % sequence of future inputs
    x = sdpvar(repmat(nx,1,N+1), repmat(1,1,N+1), 'full'); % sequence of future states
    
    % add for soft constraints
    e = sdpvar(repmat(nx,1,N), repmat(1,1,N), 'full');
    
    sdpvar r
    sdpvar u_prev

    xss = [curr_r; 0; 0; 0];
    uss = 0;
    
    % placeholder to solve at every timestep
    x_init = sdpvar(nx, 1);   % current state of the pendulum
    ref = sdpvar(1, 1);       % The target angle
    u_prev = sdpvar(1, 1);    % previous voltage (for rate limit)

    % objective and constraints
    objective = 0;
    constraints = [];

    rho_soft = 1000;
    use_soft_state = true;     % soft state on or off

    x_ref_vec = [0; ref; 0; 0];     % want alpha to be ref angle

    constraints = [constraints, x{1} == x_init];

    current_u_prev = u_prev;        % temp variable for rate limiting

    % decision vars over the time horizon
    for k = 1:N
        % objective function (Cost)
        % objective = objective + (xss - x{k})' * Q * (xss - x{k}) + (uss - u{k})' * R * (uss - u{k});

        % system dynamics constraint
        % x(k+1) = Ad * x(k) + Bd * u(k)
        constraints = [constraints, x{k+1} == Ad * x{k} + Bd * u{k}];
        
        % input magnitude constraints (hard limits)
        constraints = [constraints, u_min <= u{k} <= u_max];
        
        % input rate constraints (max rate of voltage change)
        % |u(k) - u(k-1)| <= du_max
        constraints = [constraints, -du_max <= u{k} - current_u_prev <= du_max];
        
        % state constraints
        if ~use_soft_state
            % Hard state box (Original logic)
            constraints = [constraints, x_min <= x{k} <= x_max];
            
            % Standard Cost
            objective = objective + (xss - x{k})' * Q * (xss - x{k}) ...
                                  + (uss - u{k})' * R * (uss - u{k});
        else
            % Soft state box with slack (Requested logic)
            % x_min - e{k} <= x{k} <= x_max + e{k}
            constraints = [constraints, x_min - e{k} <= x{k} <= x_max + e{k}];
            
            % Slack must be positive (e{k} >= 0)
            constraints = [constraints, e{k} >= 0];
            
            % Cost: Tracking Error + Control Effort + Slack Penalty
            objective = objective + (xss - x{k})' * Q * (xss - x{k}) ...
                                  + (uss - u{k})' * R * (uss - u{k}) ...
                                  + rho_soft * (e{k}' * e{k});
        end
        
        % update previous u for the next step in the loop
        current_u_prev = u{k};
    end
    
    % terminal cost (P) added to the final state
    final_error = x{N+1} - x_ref_vec;
    objective = objective + final_error' * P * final_error;

    % make optimiser object
    ops = sdpsettings('solver', 'quadprog', 'verbose', 0); % Use 'quadprog' or 'osqp'
    Controller = optimizer(constraints, objective, ops, {x_init, ref}, u{1});     % output: first optimal input
    end

    % runtime execution & solve
    % Pass inputs as a cell array
    [y, error_code] = Controller{{curr_x, curr_r}};

    % check for error
    if error_code ~= 0
        % if solver fails, output 0 (safety) and warn
        warning('MPC Solver Failed! Error Code: %d', error_code);
        y = 0;
    end
end